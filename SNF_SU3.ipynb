{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCoQH0wGf0PX"
      },
      "source": [
        "# SNFs for $d=3+1$ lattice $\\textrm{SU}(3)$\n",
        "Andrea Bulgarelli, Elia Cellini and Alessandro Nada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8Ez4yjRf0PY"
      },
      "source": [
        "The following notebook provides an introduction to the code used in our paper **[Scaling of Stochastic Normalizing Flows in $\\textrm{SU}(3)$ lattice gauge theory](https://arxiv.org/abs/2412.00200)**, if this code is useful for your research, please cite us:\n",
        "\n",
        "\n",
        "```\n",
        "@article{Bulgarelli:2024brv,\n",
        "    author = \"Bulgarelli, Andrea and Cellini, Elia and Nada, Alessandro\",\n",
        "    title = \"{Scaling of Stochastic Normalizing Flows in $\\mathrm{SU}(3)$ lattice gauge theory}\",\n",
        "    eprint = \"2412.00200\",\n",
        "    archivePrefix = \"arXiv\",\n",
        "    primaryClass = \"hep-lat\",\n",
        "    month = \"11\",\n",
        "    year = \"2024\"\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnL2WDUFf0PZ"
      },
      "source": [
        "<ins>**For an introduction on Stochastic Normalizing Flows for lattice field theory, see also this notebook: [SNF_for_LFT](https://github.com/TurinLatticeFieldTheoryGroup/SNF_for_LFT)**</ins>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlpooCicf0PZ"
      },
      "source": [
        "The algorithm presented in this notebook is a **Stochastic Normalizing Flows (SNF)** made by interleaving deterministic gauge equivariant layers and stochastic Monte Carlo updates. In the following, we will introduce the stochastic parts, and then the deterministic ones. In the last section, we will train and test a simple SNF.\n",
        "\n",
        "Although some parts of the code are written for a general number of colors $N$, and dimensions $D$, this implementation works only for $N=3$ and $D=4$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7qPB8H7f0PZ"
      },
      "source": [
        "## Utility Stuff for SU(3) calculations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YszunnrCf0PZ"
      },
      "source": [
        "The main two libraries used in this implementation are NumPy and PyTorch. The low-level parts of the code are not discussed in this notebook. Please proceed by running and skipping to the next section.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0UCBGRHjIbFe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.checkpoint as checkpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuGNqsUAIe4u",
        "outputId": "aea32a2a-5c95-4f79-ac09-84a915d300dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TORCH DEVICE: cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch_device = 'cuda'\n",
        "    float_dtype = np.float64\n",
        "    torch.set_default_dtype(torch.float64)\n",
        "    torch.set_default_device('cuda') #some parts of the code require to be hardfixed on GPU (if avible)\n",
        "else:\n",
        "    torch_device = 'cpu'\n",
        "    float_dtype = np.float64\n",
        "    torch.set_default_dtype(torch.float64)\n",
        "\n",
        "print(f\"TORCH DEVICE: {torch_device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sTTrLWflIew2"
      },
      "outputs": [],
      "source": [
        "#### Utility\n",
        "def torch_mod(x):\n",
        "    return torch.remainder(x, 2*np.pi)\n",
        "def torch_wrap(x):\n",
        "    return torch_mod(x+np.pi) - np.pi\n",
        "def grab(var):\n",
        "    return var.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "def SUN_identity(init_shape):\n",
        "    id = torch.ones(init_shape, dtype=torch.cdouble)\n",
        "    return torch.diag_embed(id)\n",
        "\n",
        "def SUN_determinant(cfgs):\n",
        "    return torch.linalg.det(cfgs)\n",
        "\n",
        "def SUN_trace(cfgs):\n",
        "    return torch.einsum('...ii', cfgs)\n",
        "\n",
        "def check_determinant_SUN(cfgs, tol):\n",
        "    dtm = SUN_determinant(cfgs)\n",
        "    return (dtm - 1.0).abs() > tol\n",
        "\n",
        "def SUN_dagger(cfgs):\n",
        "    return torch.conj(torch.transpose(cfgs,-2,-1))\n",
        "\n",
        "def SUN_mul(U,V):\n",
        "    return torch.einsum('...ij,...jk->...ik',U,V)\n",
        "\n",
        "def plaquette_SUN(cfgs, D, N):\n",
        "    retr = torch.zeros(cfgs[:,0].shape[:-2], dtype = torch.double)\n",
        "    dims = range(1,D+1)\n",
        "    for nu in range(1,D):\n",
        "        for mu in range(0,nu):\n",
        "            plaq = SUN_mul(SUN_dagger(cfgs[:,nu]),cfgs[:,mu])\n",
        "            plaq = SUN_mul(plaq,torch.roll(cfgs,1,dims=(-D + mu - 2))[:,nu])\n",
        "            plaq = SUN_mul(plaq, SUN_dagger(torch.roll(cfgs,1,dims=(-D + nu - 2)))[:,mu])\n",
        "            retr += SUN_trace(plaq).real\n",
        "    return torch.mean(retr, tuple(dims))/(D*(D-1)/2)/N\n",
        "\n",
        "\n",
        "def create_mask(D, T, L):\n",
        "    mask_shape = (2*D,D,T)\n",
        "    for i in range(1,D):\n",
        "        mask_shape += (L,)\n",
        "\n",
        "    mask = torch.zeros(mask_shape, dtype = int)\n",
        "    for mu in range(D):\n",
        "        for t in range(T):\n",
        "            for x in range(L):\n",
        "                if(D>2):\n",
        "                    for y in range(L):\n",
        "                        if(D>3):\n",
        "                            for z in range(L):\n",
        "                                parity = t + x + y + z\n",
        "                                mask[parity%2+mu*2,mu,t,x,y,z] = 1\n",
        "                        else:\n",
        "                            parity = t + x + y\n",
        "                            mask[parity%2+mu*2,mu,t,x,y] = 1\n",
        "                else:\n",
        "                    parity = t + x\n",
        "                    mask[parity%2+mu*2,mu,t,x] = 1\n",
        "\n",
        "    return mask.unsqueeze(1).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "def pstaple(cfgs, mu, nu, D):\n",
        "    pstaple = SUN_mul(torch.roll(cfgs,1,dims=(-D + mu - 2))[:,nu], SUN_dagger(torch.roll(cfgs,1,dims=(-D + nu - 2)))[:,mu])\n",
        "    return SUN_mul(pstaple, SUN_dagger(cfgs[:,nu]))\n",
        "\n",
        "def nstaple(cfgs, mu, nu, D):\n",
        "    nstaple = SUN_mul(SUN_dagger(torch.roll(cfgs,(1,-1),dims=(-D + mu - 2,-D + nu - 2))[:,nu]), SUN_dagger(torch.roll(cfgs,-1,dims=(-D + nu - 2)))[:,mu])\n",
        "    return SUN_mul(nstaple, torch.roll(cfgs,-1,dims=(-D + nu - 2))[:,nu])\n",
        "\n",
        "### heatbath\n",
        "\n",
        "def sum_of_staples(cfgs, mu, D, device):\n",
        "    staple = torch.zeros(cfgs[:,0].shape, dtype=torch.cdouble).to(device)\n",
        "    for nu in range(D):\n",
        "        if nu != mu:\n",
        "            pstaple = SUN_mul(torch.roll(cfgs,1,dims=(-D + mu - 2))[:,nu],\n",
        "                              SUN_dagger(torch.roll(cfgs,1,dims=(-D + nu - 2)))[:,mu])\n",
        "            pstaple = SUN_mul(pstaple, SUN_dagger(cfgs[:,nu]))\n",
        "            staple += pstaple\n",
        "            nstaple = SUN_mul(SUN_dagger(torch.roll(cfgs,(1,-1),dims=(-D + mu - 2,-D + nu - 2))[:,nu]),\n",
        "                              SUN_dagger(torch.roll(cfgs,-1,dims=(-D + nu - 2)))[:,mu])\n",
        "            nstaple = SUN_mul(nstaple, torch.roll(cfgs,-1,dims=(-D + nu - 2))[:,nu])\n",
        "            staple += nstaple\n",
        "\n",
        "    return staple\n",
        "\n",
        "def SU2_element(mat, i, j):\n",
        "    return torch.index_select(torch.index_select(mat,-2,i),-1,j).squeeze(-1).squeeze(-1)\n",
        "\n",
        "def SU2toSU3(Ak, phb, device):\n",
        "    A = torch.zeros(Ak.shape[:-2] + (2,1)).to(device)\n",
        "    B = torch.cat((torch.index_select(Ak,-1,torch.arange(phb)),A,torch.index_select(Ak,-1,torch.arange(phb,2))),-1)\n",
        "    A = torch.zeros(Ak.shape[:-2] + (1,2)).to(device)\n",
        "    C = torch.ones(Ak.shape[:-2] + (1,1)).to(device)\n",
        "    AA = torch.cat((torch.index_select(A,-1,torch.arange(phb)),C,torch.index_select(A,-1,torch.arange(phb,2))),-1)\n",
        "    return torch.cat((torch.index_select(B,-2,torch.arange(phb)),AA,torch.index_select(B,-2,torch.arange(phb,2))),-2)\n",
        "\n",
        "\n",
        "def heatbath(prefactor, mu, D, rand, device):\n",
        "    #WARNING: if rand[:,0] and one of the two other rand are simultaneously 0 a NaN occurs in the gradient of mod. Probably very unlikely\n",
        "    lam2 = (- 1.0 / (2.0 * prefactor) * (rand[:,0,mu,:] + rand[:,1,mu,:] * rand[:,2,mu,:]))\n",
        "    acc = (1.0 - lam2 >= rand[:,3,mu,:]**2)\n",
        "\n",
        "    x0 = (1.0 - 2.0 * lam2) * acc\n",
        "    #x0=x0.detach() # This detach prevents (unlikely) NaN in the gradient of the square root mod\n",
        "    stheta = torch.sqrt(1.0 - rand[:,4,mu,:]**2)\n",
        "    mod = torch.sqrt(1.0 - x0**2)\n",
        "\n",
        "    A = torch.complex(x0, mod*rand[:,4,mu,:]).unsqueeze(-1)\n",
        "    B = (stheta*mod*torch.complex(torch.cos(rand[:,5,mu,:]), torch.sin(rand[:,5,mu,:]))).unsqueeze(-1)\n",
        "    Xa = torch.ones(prefactor.shape + (1,)).to(device) * A\n",
        "    Xb = torch.ones(prefactor.shape + (1,)).to(device) * B\n",
        "    X = torch.cat((Xa,Xb),-1)\n",
        "\n",
        "    v1 = torch.conj((X * torch.tensor([1,-1]).view([1]*(len(X.shape)-1)+[2])).roll(1,-1))\n",
        "    Xmat = torch.cat((X.unsqueeze(-2),v1.unsqueeze(-2)),-2)\n",
        "    acc = acc.unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "    return Xmat, acc\n",
        "\n",
        "\n",
        "def SU3_compute_RK(new_cfgs, staples, sel, phb):\n",
        "    sel2 = sel[sel != phb]\n",
        "    Rk = SUN_mul(new_cfgs, staples)# SUN_dagger(staples))\n",
        "\n",
        "    #generate SU(2) subgroup matrix from Rk\n",
        "    a = 0.5*(SU2_element(Rk,sel2[0],sel2[0]) + torch.conj(SU2_element(Rk,sel2[1],sel2[1]))).unsqueeze(-1)\n",
        "    b = 0.5*(SU2_element(Rk,sel2[0],sel2[1]) - torch.conj(SU2_element(Rk,sel2[1],sel2[0]))).unsqueeze(-1)\n",
        "    v0 = torch.cat((a,b),-1)\n",
        "    v1 = torch.conj((v0 * torch.tensor([1,-1]).view([1]*(len(v0.shape)-1)+[2])).roll(1,-1))\n",
        "    Rk = torch.cat((v0.unsqueeze(-2),v1.unsqueeze(-2)),-2)\n",
        "    k = torch.sqrt(SUN_determinant(Rk).abs())\n",
        "    Rk = Rk / k.unsqueeze(-1).unsqueeze(-1)\n",
        "    return Rk, k\n",
        "\n",
        "def SU3_link_update_hb(beta, cfgs, mu, D, rand, device):\n",
        "    #staples = sum_of_staples(cfgs, mu, D, device)\n",
        "    staples = checkpoint.checkpoint(sum_of_staples, cfgs, mu, D, device, use_reentrant=False)\n",
        "    phb_steps = 3\n",
        "    new_cfgs = cfgs[:,mu]\n",
        "    sel = torch.tensor([0,1,2]).to(device)\n",
        "    for phb in range(phb_steps):\n",
        "        Rk, k = SU3_compute_RK(new_cfgs, staples, sel, phb)\n",
        "        Xmat, acc = heatbath(2.0*beta*k/3.0, mu, D, rand[:,6*phb:6*(phb+1),:], device)\n",
        "        Ak = SUN_mul(Xmat, SUN_dagger(Rk))\n",
        "        Ak = SU2toSU3(Ak, phb, device)\n",
        "        new_cfgs = SUN_mul(Ak, new_cfgs) * acc + new_cfgs * ~acc\n",
        "    return new_cfgs.unsqueeze(1)\n",
        "\n",
        "def SU3_link_update_over(cfgs, mu, D, device):\n",
        "    #staples = sum_of_staples(cfgs, mu, D, device)\n",
        "    staples = checkpoint.checkpoint(sum_of_staples, cfgs, mu, D, device, use_reentrant=False)\n",
        "    phb_steps = 3\n",
        "    new_cfgs = cfgs[:,mu]\n",
        "    sel = torch.tensor([0, 1, 2])\n",
        "    for phb in range(phb_steps):\n",
        "        Rk, k = SU3_compute_RK(new_cfgs, staples, sel, phb)\n",
        "        i0 = torch.tensor([0])\n",
        "        i1 = torch.tensor([1])\n",
        "        a = (SU2_element(Rk,i1,i1)*SU2_element(Rk,i1,i1)+SU2_element(Rk,i0,i1)*SU2_element(Rk,i1,i0)).unsqueeze(-1)\n",
        "        b = (-SU2_element(Rk,i1,i1)*SU2_element(Rk,i0,i1)-SU2_element(Rk,i0,i1)*SU2_element(Rk,i0,i0)).unsqueeze(-1)\n",
        "        v0 = torch.cat((a,b),-1)\n",
        "        v1 = torch.conj((v0 * torch.tensor([1,-1]).view([1]*(len(v0.shape)-1)+[2])).roll(1,-1))\n",
        "        Ak = torch.cat((v0.unsqueeze(-2),v1.unsqueeze(-2)),-2)\n",
        "        #bring Ak back to SU(3)\n",
        "        Ak = SU2toSU3(Ak, phb, device)\n",
        "        #new link is Ak*old_link\n",
        "        new_cfgs = SUN_mul(Ak, new_cfgs)\n",
        "    return new_cfgs.unsqueeze(1)\n",
        "\n",
        "\n",
        "def init_hb(mask, orsteps, rn_shape, init_shape):\n",
        "    D=4\n",
        "    hb_update=SU3_link_update_hb\n",
        "    over_update=SU3_link_update_over\n",
        "\n",
        "    def update(cfgs, beta, device):\n",
        "        rand = torch.rand(rn_shape).to(device)\n",
        "        for rr in range(rn_shape[1]//6):\n",
        "            rand[:,rr*6] = torch.log(1.0 - rand[:,rr*6])\n",
        "            rand[:,rr*6+1] = torch.cos(2.0 * torch.pi *(1.0 - rand[:,rr*6+1]))**2\n",
        "            rand[:,rr*6+2] = torch.log(1.0 - rand[:,rr*6+2])\n",
        "            rand[:,rr*6+4] = 1.0 - 2.0 * rand[:,rr*6+4]\n",
        "            rand[:,rr*6+5] = 2.0 * torch.pi * rand[:,rr*6+5]\n",
        "\n",
        "        for mu in range(D):\n",
        "            for eo in range(2):\n",
        "                current_mask = mask[eo+mu*2,:]\n",
        "                cfgs_new = hb_update(beta, cfgs, mu, D, rand, device)\n",
        "                cfgs = current_mask * cfgs_new + (1-current_mask) * cfgs\n",
        "\n",
        "        for o in range(orsteps):\n",
        "            for mu in range(D):\n",
        "                for eo in range(2):\n",
        "                    current_mask = mask[eo+mu*2,:]\n",
        "                    cfgs_new = over_update(cfgs, mu, D, device)\n",
        "                    cfgs = current_mask * cfgs_new + (1-current_mask) * cfgs\n",
        "        return cfgs\n",
        "\n",
        "    return update\n",
        "\n",
        "\n",
        "\n",
        "#functions for smearing:\n",
        "def xi0(w, w2):\n",
        "    return torch.where(torch.abs(w) > 0.005, torch.sin(w)/w, 1. - 1./6.*w2*(1. - 1./20.*w2*(1. - 1./42.*w2)))\n",
        "\n",
        "def xi1(w, w2):\n",
        "    return torch.where(torch.abs(w) > 0.005, torch.cos(w)/w2 - torch.sin(w)/w**3,\n",
        "                       -1./3. + w2*(1./30. + w2*(-1./840 + 1./45360.*w2)))\n",
        "\n",
        "def xi2(w, w2, xizero, xione):\n",
        "    return torch.where(torch.abs(w) > 0.005, 1./w2*(xizero + 3. * xione), -1./15. + w2*(1./210. - w2/7560.))\n",
        "\n",
        "#stuff for Jacobian\n",
        "def otimes(A,B):\n",
        "    return torch.einsum('...ij,...kl->...ijkl',A,B)\n",
        "\n",
        "def oplus(A,B):\n",
        "    return torch.einsum('...kj,...il->...ijkl',A,B)\n",
        "\n",
        "def starprod(A,B):\n",
        "    return torch.einsum('...inml,...njkm->...ijkl',A,B)\n",
        "\n",
        "def starprodmat(A,B):\n",
        "    return torch.einsum('...ijkn,...nl->...ijkl',A,B)\n",
        "\n",
        "def matstarprod(A,B):\n",
        "    return torch.einsum('...in,...njkl->...ijkl',A,B)\n",
        "\n",
        "def generate_coefficients(Q, Q2, id, oidid, oidQ, device):\n",
        "    c0 = SUN_determinant(Q)\n",
        "    c1 = .5 * SUN_trace(Q2)\n",
        "    c0max = 2.0 * (c1 / 3.0)**1.5\n",
        "\n",
        "    sgnc0 = torch.real(torch.sgn(c0))\n",
        "    c0 = torch.abs(c0)\n",
        "\n",
        "    theta = torch.arccos(c0/c0max)\n",
        "    u = torch.sqrt(c1/3.0) * torch.cos(theta/3.0)\n",
        "    w = torch.sqrt(c1) * torch.sin(theta/3.0)\n",
        "    u2 = u**2\n",
        "    w2 = w**2\n",
        "    cw = torch.cos(w)\n",
        "    eu = torch.cos(u) + 1.j*torch.sin(u)\n",
        "    eu2 = eu**2\n",
        "    eum = eu**(-1)\n",
        "\n",
        "    xizero = xi0(w, w2)\n",
        "    xione = xi1(w, w2)\n",
        "\n",
        "    h0 = (u2 - w2)*eu2 + eum*(8.*u2*cw + 2.j*u*(3.*u2 + w2)*xizero)\n",
        "    h1 = 2.*u*eu2 - eum*(2.*u*cw - 1.j*(3.*u2 - w2)*xizero)\n",
        "    h2 = eu2 - eum*(cw + 3.j*u*xizero)\n",
        "\n",
        "    r10 = 2.*(u + 1.j*(u2 - w2))*eu2 + 2.*eum*(4.*u*(2.-1.j*u)*cw + 1.j*(9.*u2 + w2 - 1.j*u*(3.*u2 + w2)) * xizero)\n",
        "    r11 = 2.*(1. + 2.j*u)*eu2 + eum*(-2.*(1.-1.j*u)*cw + 1.j*(6.*u + 1.j*(w2 - 3.*u2))*xizero)\n",
        "    r12 = 2.j*eu2 + 1.j*eum*(cw - 3.*(1.-1.j*u)*xizero)\n",
        "    r20 = -2.*eu2 + 2.j*u*eum*(cw + (1.+4.j*u)*xizero + 3.*u2*xione)\n",
        "    r21 = -1.j*eum*(cw + (1.+2.j*u)*xizero - 3.*u2*xione)\n",
        "    r22 = eum * (xizero - 3.j*u*xione)\n",
        "\n",
        "    den = 9.*u2 - w2\n",
        "    den2 = 2. * den**2\n",
        "    v3u2mw2 = 3.*u2 - w2\n",
        "    v15u2pw2 = 15.*u2 + w2\n",
        "\n",
        "    f0 = h0 / den\n",
        "    f1 = h1 / den\n",
        "    f2 = h2 / den\n",
        "\n",
        "    b10 = (2.*u*r10 + v3u2mw2 * r20 - 2.*v15u2pw2*f0) / den2\n",
        "    b11 = (2.*u*r11 + v3u2mw2 * r21 - 2.*v15u2pw2*f1) / den2\n",
        "    b12 = (2.*u*r12 + v3u2mw2 * r22 - 2.*v15u2pw2*f2) / den2\n",
        "    b20 = (r10 - 3.*u*r20 - 24.*u*f0) / den2\n",
        "    b21 = (r11 - 3.*u*r21 - 24.*u*f1) / den2\n",
        "    b22 = (r12 - 3.*u*r22 - 24.*u*f2) / den2\n",
        "\n",
        "    f0 = torch.where(sgnc0 > 0, f0, torch.conj(f0))\n",
        "    f1 = torch.where(sgnc0 > 0, f1, -torch.conj(f1))\n",
        "    f2 = torch.where(sgnc0 > 0, f2, torch.conj(f2))\n",
        "\n",
        "    b10 = torch.where(sgnc0 > 0, b10, torch.conj(b10))\n",
        "    b11 = torch.where(sgnc0 > 0, b11, -torch.conj(b11))\n",
        "    b12 = torch.where(sgnc0 > 0, b12, torch.conj(b12))\n",
        "    b20 = torch.where(sgnc0 > 0, b20, -torch.conj(b20))\n",
        "    b21 = torch.where(sgnc0 > 0, b21, torch.conj(b21))\n",
        "    b22 = torch.where(sgnc0 > 0, b22, -torch.conj(b22))\n",
        "\n",
        "    B1 = b10.unsqueeze(-1).unsqueeze(-1) * id + b11.unsqueeze(-1).unsqueeze(-1) * Q +\\\n",
        "         + b12.unsqueeze(-1).unsqueeze(-1) * Q2\n",
        "    B2 = b20.unsqueeze(-1).unsqueeze(-1) * id + b21.unsqueeze(-1).unsqueeze(-1) * Q +\\\n",
        "         + b22.unsqueeze(-1).unsqueeze(-1) * Q2\n",
        "\n",
        "    return f0.unsqueeze(-1).unsqueeze(-1), f1.unsqueeze(-1).unsqueeze(-1), f2.unsqueeze(-1).unsqueeze(-1), B1, B2\n",
        "\n",
        "def generate_omega(C, U):\n",
        "    return SUN_mul(C, SUN_dagger(U))\n",
        "\n",
        "def generate_Q(omega, N):\n",
        "    antiherm = SUN_dagger(omega) - omega\n",
        "    return 0.5 * 1.j* (antiherm) - 0.5 * 1.j / N * SUN_trace(antiherm).unsqueeze(-1).unsqueeze(-1) * SUN_identity(antiherm.shape[:-1])\n",
        "\n",
        "def generate_expQ(Q, Q2, id, f0, f1, f2):\n",
        "    return f0 * id + f1 * Q + f2 * Q2\n",
        "\n",
        "def generate_dQ_domega(N, oidid, id):\n",
        "    A = oidid\n",
        "    B = oplus(id, id)\n",
        "    return -1.j*(.5 * A - .5/N * B)\n",
        "\n",
        "def generate_dexpQ_dQ(Q, Q2, B1, B2, f1, f2, id, oidid, oidQ):\n",
        "    M = oplus(Q, B1)\n",
        "    M += oplus(Q2, B2)\n",
        "    M += f1.unsqueeze(-1).unsqueeze(-1)*oidid\n",
        "    M += f2.unsqueeze(-1).unsqueeze(-1)*oidQ\n",
        "    return M\n",
        "\n",
        "def generate_domega_dU(C, id):\n",
        "    return -otimes(id, SUN_dagger(C))\n",
        "\n",
        "def generate_domega_dC(U, oidid):\n",
        "    return starprodmat(oidid, SUN_dagger(U))\n",
        "\n",
        "def generate_dQ_dU(dQdomega, id, C):\n",
        "    B = generate_domega_dU(C, id)\n",
        "    return starprod(dQdomega, B)\n",
        "\n",
        "def generate_dQ_dC(dQdomega, oidid, U):\n",
        "    B = generate_domega_dC(U, oidid)\n",
        "    return starprod(dQdomega, B)\n",
        "\n",
        "def generate_dexpQ_dU(dexpQdQ, dQ_dU):\n",
        "    return starprod(dexpQdQ, dQ_dU)\n",
        "\n",
        "def generate_Jacobian_U(dexpQdU, U, expQ, oidid):\n",
        "    return starprodmat(dexpQdU, U) + matstarprod(expQ, oidid)\n",
        "\n",
        "def generate_Jacobian_C(dexpQdQ, dQdC, U):\n",
        "    A = starprod(dexpQdQ, dQdC)\n",
        "    return starprodmat(A, U)\n",
        "\n",
        "def Jacobian_reshape(jac, jac_shape):\n",
        "    return torch.einsum('...ijkl->...iljk',jac).reshape(jac_shape)\n",
        "\n",
        "def det_Jac(J):\n",
        "    return torch.linalg.det(J)\n",
        "\n",
        "def stout_staples(cfgs, mu, rho, device):\n",
        "    staple = torch.zeros(cfgs[:,0].shape, dtype=torch.cdouble).to(device)\n",
        "    if len(rho) == 1:\n",
        "        for nu in range(4):\n",
        "            if nu != mu:\n",
        "                staple += rho * (SUN_dagger(pstaple(cfgs, mu, nu, 4)) + SUN_dagger(nstaple(cfgs, mu, nu, 4)))\n",
        "    else:\n",
        "        for nu in range(4):\n",
        "            if nu != mu:\n",
        "                staple += rho[nu] * (SUN_dagger(pstaple(cfgs, mu, nu, 4)) + SUN_dagger(nstaple(cfgs, mu, nu, 4)))\n",
        "    return staple\n",
        "\n",
        "def stout_smearing(cfgs, mu, rho, jac_shape, device):\n",
        "    C = checkpoint.checkpoint(stout_staples, cfgs, mu, rho, device, use_reentrant=False, preserve_rng_state=False)\n",
        "\n",
        "    U = cfgs[:,mu]\n",
        "    id = SUN_identity(U.shape[:-1])\n",
        "    N = U.shape[-1]\n",
        "    omega = generate_omega(C, U)\n",
        "    Q = generate_Q(omega, N)\n",
        "    Q2 = SUN_mul(Q, Q)\n",
        "\n",
        "    oidid = otimes(id, id)\n",
        "    oidQ = otimes(id, Q) + otimes(Q, id)\n",
        "\n",
        "    f0, f1, f2, B1, B2 = generate_coefficients(Q, Q2, id, oidid, oidQ, device)\n",
        "    expQ = generate_expQ(Q, Q2, id, f0, f1, f2)\n",
        "    dexpQdQ = generate_dexpQ_dQ(Q, Q2, B1, B2, f1, f2, id, oidid, oidQ)\n",
        "\n",
        "    dQdomega = generate_dQ_domega(N, oidid, id)\n",
        "    dQdU = generate_dQ_dU(dQdomega, id, C)\n",
        "    dexpQdU = generate_dexpQ_dU(dexpQdQ, dQdU)\n",
        "    Jacobian_U = generate_Jacobian_U(dexpQdU, U, expQ, oidid)\n",
        "    detjac = det_Jac(Jacobian_reshape(Jacobian_U, jac_shape)).abs()\n",
        "\n",
        "    return SUN_mul(expQ, U).unsqueeze(1), detjac.unsqueeze(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Lr0nUaf0Pa"
      },
      "source": [
        "## Target Action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPNGmAHnf0Pb"
      },
      "source": [
        "In this notebook, we target $\\textrm{SU}(3)$ gauge theory in $d=3+1$ dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fC-YjyZbIqbO"
      },
      "outputs": [],
      "source": [
        "class S_SUN:\n",
        "    def __init__(self, D=4,N=3):\n",
        "      self.D=D #Dimensions\n",
        "      self.N=N #Colors\n",
        "    def __call__(self,cfgs, beta):\n",
        "      retr = torch.zeros(cfgs[:,0].shape[:-2], dtype = torch.double)\n",
        "      dims = range(1,self.D+1)\n",
        "      for nu in range(1,self.D):\n",
        "          for mu in range(0,nu):\n",
        "              plaq = SUN_mul(SUN_dagger(cfgs[:,nu]),cfgs[:,mu])\n",
        "              plaq = SUN_mul(plaq,torch.roll(cfgs,1,dims=(-self.D + mu - 2))[:,nu])\n",
        "              plaq = SUN_mul(plaq,SUN_dagger(torch.roll(cfgs,1,dims=(-self.D + nu - 2)))[:,mu])\n",
        "              retr += SUN_trace(plaq).real\n",
        "\n",
        "      return beta*torch.sum(6.0 - retr/self.N, tuple(dims))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE6pOQN-f0Pb"
      },
      "source": [
        "## Prior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4SsXHVRf0Pb"
      },
      "source": [
        "In our work, we used a thermalized MCMC as a prior for our SNFs, implemented in the following class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BYGzVwuYIqX3"
      },
      "outputs": [],
      "source": [
        "class PriorSUN:\n",
        "    def __init__(self, init_shape, action, beta, update, therm_steps, mcmc_steps, device):\n",
        "        '''\n",
        "        This class implements a standard MCMC used as a prior for our SNFs.\n",
        "        Given a general MCMC update, the class thermalizes a batch of replicas\n",
        "        at fixed action and then runs a standard MCMC over these samples.\n",
        "        !This class doesn't work for beta=0!\n",
        "        '''\n",
        "        self.init_shape=init_shape\n",
        "        self.update=update\n",
        "        self.beta=beta\n",
        "        self.therm_steps=therm_steps #thermalization steps\n",
        "        self.mcmc_steps=mcmc_steps #sweep steps\n",
        "        self.action=action\n",
        "        self.device=device\n",
        "\n",
        "    def __call__(self, cfgs=None):\n",
        "        if cfgs != None:\n",
        "            with torch.no_grad():\n",
        "                for i in range(self.mcmc_steps):\n",
        "                    cfgs = self.update(cfgs, self.beta, self.device)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                cfgs = self.therm()\n",
        "        return cfgs, self.action(cfgs, self.beta)\n",
        "\n",
        "    def therm(self):\n",
        "        cfgs = SUN_identity(self.init_shape).to(self.device)\n",
        "        for i in range(self.therm_steps):\n",
        "            cfgs = self.update(cfgs, self.beta, self.device)\n",
        "        return cfgs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8wdRdjBf0Pb"
      },
      "source": [
        "## Non-Equilibrium MCMC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTPL2yjif0Pb"
      },
      "source": [
        "The main core of the Non-Equilibrium MCMC used in our work is the heatbath update (see the textbook [Quantum fields on a lattice](https://inspirehep.net/literature/378182))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_4_5fIbf0Pb"
      },
      "source": [
        "Given an MCMC update, the stochastic layer is very simple. Defining the input sample as $U_i$ and the stochastic layer $sl$,\n",
        "the output $U_o$ is obtained by applying the stochastic update to the input: $U_o=sl(U_i)$. The pseudoheat $Q$ is then computed as the difference between the action of the input and the target: $Q=S(U_o)-S(U_i)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_yDrbOzxf0Pb"
      },
      "outputs": [],
      "source": [
        "class NEMCMC_update(torch.nn.Module):\n",
        "    def __init__(self,action, beta,update,device):\n",
        "        '''\n",
        "        This class implement a NE-MCMC step wrapped in a pytorch module.\n",
        "        The action and the coupling beta are given by the chosen protocol while\n",
        "        the update can be a general MCMC transformation that satisfy detailed balance\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.action=action #action fixed in the MCMC update\n",
        "        self.update = update #choosen update\n",
        "        self.beta = beta #coupling of the action\n",
        "        self.device = device\n",
        "    def forward(self,cfgs):\n",
        "        s_old=self.action(cfgs,self.beta)\n",
        "        cfgs=self.update(cfgs,self.beta,self.device) #get the new samples\n",
        "        return cfgs, self.action(cfgs,self.beta)-s_old, 0 #output: new configurations and Q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0H2aNKVf0Pb"
      },
      "source": [
        "## Gauge Equivariant Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c269KI6f0Pb"
      },
      "source": [
        "In our code, we used a gauge equivariant network inspired by [[Nagai and Tomiya; 2103.11965](https://arxiv.org/abs/2103.11965)] and [[Abbott et al.;2305.02402](https://arxiv.org/abs/2305.02402)], see also [[Morningstar and Peardon; hep-lat/0311018](https://arxiv.org/abs/hep-lat/0311018)].  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFVEdP8vf0Pb"
      },
      "source": [
        "The following class implements the gauge quivariant layer. Each layer $g_i$ computes the output $U_i=g_i(U_{i-1})$ and the logarithm of the Jacobian of the transformation. To simplify the computation of the Jacobian, we used even-odd masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nuFPZkVhf0Pb"
      },
      "outputs": [],
      "source": [
        "class Smearing(torch.nn.Module):\n",
        "    def __init__(self, mask,  jac_shape, scale_fac, rho_shape, device, rho_root=None, smearing_steps=1):\n",
        "        '''\n",
        "        Gauge equivariant layer for our SNF. The transformation is a stout\n",
        "        smearing with learnable parameters, the square root of which\n",
        "        is the matrix rho_root. This class can be used as a \"deep\" neural network,\n",
        "        where the number of layers is determined by the parameter smearing_steps.\n",
        "        The shape of rho_root is (smearing_steps, 2* Dimensions, 4)  one rho for each dims\n",
        "        or  (smearing_steps, 2* Dimensions, 1) same rho for each dims\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.mask = mask\n",
        "        self.smearing_steps = smearing_steps #numbers of layers for each coupling layer, default 1\n",
        "        #The class can take as input a trained set of parameters in order to easily transfer them among different models\n",
        "        if rho_root is None:\n",
        "            self.rho_root = torch.nn.Parameter(torch.rand(rho_shape).to(device) * scale_fac)\n",
        "        else:\n",
        "            self.rho_root = torch.nn.Parameter(rho_root)\n",
        "\n",
        "        self.jac_shape = jac_shape\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, cfgs):\n",
        "        ones = (torch.ones(self.mask[0].shape, dtype=torch.double).squeeze(-1).squeeze(-1)).to(self.device)\n",
        "        bs = cfgs.shape[0]\n",
        "        dlogJ = torch.zeros(bs, dtype=torch.double).to(self.device)\n",
        "        dims = tuple(np.arange(1,6))\n",
        "        for sm in range(self.smearing_steps): #loops over layers of the coupling layer\n",
        "            for mu in range(4): #loops over dimensions\n",
        "                for eo in range(2): #loops over even-odd fields\n",
        "                    current_mask = self.mask[eo+mu*2,:]\n",
        "                    rho = self.rho_root[sm,eo+mu*2,:]**2\n",
        "                    cfgs_new, jac = stout_smearing(cfgs, mu, rho, self.jac_shape, self.device)\n",
        "                    cfgs = current_mask * cfgs_new + (1-current_mask) * cfgs\n",
        "                    jac = torch.log(current_mask.squeeze(-1).squeeze(-1) * jac + (1-current_mask.squeeze(-1).squeeze(-1)) * ones)\n",
        "                    dlogJ += torch.sum(jac, dims)\n",
        "        return cfgs, 0, dlogJ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPQ8O9y9f0Pc"
      },
      "source": [
        "## General class for SNF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9k6AcbWf0Pc"
      },
      "source": [
        "We can now build a general class for SNFs. The constructor of the class takes as input the target action and coupling, and list of layers.\n",
        "\n",
        "Given a batch of prior samples $U_0$ and their action $S_0(U_0)$, the class computes the generated samples $U$, the work for the evolutions $[U_0,\\cdots, U]$:\n",
        "$$W(U_0,\\cdots, U)= S(U) - S_0(U_0) - Q(U_0,\\cdots, U) -\\log J(U_0,\\cdots, U),$$\n",
        "\n",
        "where $Q(U_0,\\cdots, U)$ is the sum over the pseudoheat of each stochastic layer and $\\log J(U_0,\\cdots, U)$ is the sum of the logarithms of the Jacobians of the gauge equivariant layers.\n",
        "\n",
        "The class also computes the free energy difference between target and prior and the ESS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "im57ry9Cjfvh"
      },
      "outputs": [],
      "source": [
        "class Flow:\n",
        "    def __init__(self, action, coupling, flow):\n",
        "        super().__init__()\n",
        "        self.action=action #target action\n",
        "        self.flow = flow #list of layers\n",
        "        self.coupling = coupling #target coupling\n",
        "\n",
        "    def __call__(self,x,s0):\n",
        "        x, Q, logJ = self.forward(x) #calculation of generated sample x, Q, and logJ\n",
        "        st = self.action(x,self.coupling)\n",
        "        w = st - s0 - Q - 2.0*logJ #Calculation of the work W\n",
        "        deltaF, ess = self.compute_metrics(w)  #calculation of metrics: \\Delta F and ESS\n",
        "        return x, w, deltaF, ess\n",
        "\n",
        "    def forward(self,x): #Forward of the flow\n",
        "        Q = torch.zeros(x.shape[0])\n",
        "        logJ = torch.zeros(x.shape[0])\n",
        "        for layer in self.flow:\n",
        "            x, dQ, dlogJ = layer.forward(x)\n",
        "            Q += dQ\n",
        "            logJ += dlogJ\n",
        "        return x, Q, logJ\n",
        "\n",
        "    def compute_metrics(self,w): #Standard metrics\n",
        "        wd = w.detach()\n",
        "        DF = - torch.log(torch.mean(torch.exp(-(wd-wd.mean())))) + wd.mean()\n",
        "        ess = (torch.mean(torch.exp(-(wd-wd.mean())))**2)/torch.mean(torch.exp(-2.0*(wd-wd.mean())))\n",
        "        return DF,ess\n",
        "\n",
        "    def sample_(self,x,s0): #sample function for testing\n",
        "        with torch.no_grad():\n",
        "            x, Q, logJ = self.forward(x)\n",
        "            st = self.action(x,self.coupling)\n",
        "            w = st - s0 - Q - 2.0*logJ\n",
        "        return x, w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1awWtLokf0Pc"
      },
      "source": [
        "The following function builds an SNF (or an NE-MCMC):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8hIfZjDBtfDE"
      },
      "outputs": [],
      "source": [
        "def make_SNF(betas, action, update, mask, init_shape, jac_shape,torch_device, deterministic=True, scale_fac=0.01**4,smearing_steps=1,):\n",
        "    layers=[]\n",
        "    for b in betas: #For every beta of the protocol we add:\n",
        "        if deterministic:\n",
        "            #one deterministic layer:\n",
        "            smr=Smearing(mask,  jac_shape, scale_fac, (smearing_steps, 2*4, 4), device=torch_device)\n",
        "            layers.append(smr)\n",
        "        #one stocastic layer:\n",
        "        stb=NEMCMC_update(action, b, update, torch_device)\n",
        "        layers.append(stb)\n",
        "    flow=Flow(action, betas[-1], torch.nn.ModuleList(layers).to(torch_device))\n",
        "    return flow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to benchmark the effectivness of our SNF, we will compare  the trained model with a pure NE-MCMC (deterministic = False)"
      ],
      "metadata": {
        "id": "cJgjvgJfuTH1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWV_9iTKf0Pc"
      },
      "source": [
        "## Play with SU$(3)$ SNFs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxCEDTCNf0Pc"
      },
      "source": [
        "We can now play with our SNF, the main parameters needed to initialize the flows are:\n",
        "\n",
        "- bs: batch size\n",
        "- D: dimensions $\\to$ the code generally works only for $D=4$\n",
        "- T: temporal extension\n",
        "- L: spatial extension\n",
        "- N: colors $\\to$ this notebook works only for $N=3$\n",
        "- k(N=3)=18\n",
        "\n",
        "Shapes:\n",
        "- configurations shape = (bs, D, T, L,..., L, N, N)\n",
        "- initialization shape = (bs, D, T, L,..., L, N)\n",
        "- random numbers shape = (bs, k(N), D, T, L,..., L)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoznIsXAf0Pc"
      },
      "source": [
        "For simplicity, we will test the SNF on $4^4$ lattices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Oacp6mMNawbN"
      },
      "outputs": [],
      "source": [
        "bs=8\n",
        "T=4\n",
        "L=4\n",
        "init_shape=(bs,4,T,L,L,L,3)\n",
        "jac_shape=(bs,T,L,L,L,9,9)\n",
        "rn_shape=(bs,18,4,T,L,L,L)\n",
        "orsteps=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxUWsC6qf0Pc"
      },
      "source": [
        "Prior, target parameters and the (linear) protocol for the non-equilibrium part:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEOiJDzXq18F",
        "outputId": "2e0706cc-5853-4689-f0ae-92798c9d63a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.04, 6.08, 6.12, 6.16, 6.2 ])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "beta0=6.0 #prior beta\n",
        "beta_tar=6.2 #target beta\n",
        "steps_beta=5 #numers of steps of the protocol, i.e. NE-MCMCM updates\n",
        "betas = np.linspace(beta0 + (beta_tar - beta0)/steps_beta, beta_tar, steps_beta) # Protocol\n",
        "betas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzwOIe7qf0Pc"
      },
      "source": [
        "Let's build the SNF:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BacDCcWnawog"
      },
      "outputs": [],
      "source": [
        "action = S_SUN() #Theory SU(3) in d=3+1\n",
        "mask = create_mask(4, T, L).to(torch_device) #even-odd mask\n",
        "update = init_hb(mask, orsteps, rn_shape, init_shape) #MCMC update for prior and SNFs\n",
        "\n",
        "therm_steps= 10 #Thermalization steps for the prior\n",
        "mcmc_steps = 1 # Sweep steps for the prior\n",
        "prior = PriorSUN(init_shape, action, beta0, update, therm_steps, mcmc_steps, torch_device)\n",
        "\n",
        "flow = make_SNF(betas, action, update, mask, init_shape, jac_shape,torch_device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcyfixjMf0Pc"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb6IESyMf0Pc"
      },
      "source": [
        "We can now train the SNF using the standard procedure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "T6-NihDSqqCW"
      },
      "outputs": [],
      "source": [
        "n_epochs=100 #number of gradient update\n",
        "optimizer=torch.optim.Adam(flow.flow.parameters(), lr=0.001) #optimizer\n",
        "history={'loss':[],'ESS':[]} #saved metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1_y3aJ-vLLH",
        "outputId": "047b75d2-2378-4e46-9611-090ec74c8b7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 1, loss: 121.8532080913017, w_var: 2.077699518731076, ess: 0.4383099225293975, Delta_free_en: 121.07012990888002\n",
            "step: 2, loss: 121.73728934383732, w_var: 0.6149957843013862, ess: 0.7935011246451031, Delta_free_en: 121.54176415454862\n",
            "step: 3, loss: 122.44286872941939, w_var: 6.257695789669613, ess: 0.33163336857292486, Delta_free_en: 120.7999435843699\n",
            "step: 4, loss: 121.55046978934072, w_var: 4.156145690077399, ess: 0.36206376531040824, Delta_free_en: 120.3544702147849\n",
            "step: 5, loss: 122.11993643544922, w_var: 4.031853678752845, ess: 0.4013442301203892, Delta_free_en: 120.70631131045128\n",
            "step: 6, loss: 122.17857598336879, w_var: 1.0187379196431656, ess: 0.3780742342200825, Delta_free_en: 121.63655789510454\n",
            "step: 7, loss: 122.88734168044198, w_var: 3.796964685141129, ess: 0.466246265609837, Delta_free_en: 121.78014231782352\n",
            "step: 8, loss: 122.00771783417298, w_var: 2.036832596945048, ess: 0.4800555890702933, Delta_free_en: 121.37843204601424\n",
            "step: 9, loss: 122.37948256330685, w_var: 1.6290411621149758, ess: 0.5729822406009705, Delta_free_en: 121.83667269598786\n",
            "step: 10, loss: 121.39825748618013, w_var: 2.396428777840948, ess: 0.3126506601688642, Delta_free_en: 120.33213459711584\n",
            "step: 11, loss: 122.55818813045133, w_var: 0.7112433092444272, ess: 0.7186600072972094, Delta_free_en: 122.29482922566737\n",
            "step: 12, loss: 122.22917680018048, w_var: 2.313135261257682, ess: 0.4996785632603086, Delta_free_en: 121.50456472450455\n",
            "step: 13, loss: 122.14341859292293, w_var: 2.398536772493652, ess: 0.2317118946320356, Delta_free_en: 120.96217238662962\n",
            "step: 14, loss: 122.03911346606681, w_var: 1.758216337520153, ess: 0.538663397670081, Delta_free_en: 121.44315362697986\n",
            "step: 15, loss: 121.57656489163605, w_var: 0.9307004987404527, ess: 0.4035071010086109, Delta_free_en: 121.06447247034718\n",
            "step: 16, loss: 122.00579279981793, w_var: 1.50476382725836, ess: 0.3940328362833615, Delta_free_en: 121.32986392542024\n",
            "step: 17, loss: 122.98056824426554, w_var: 1.910739239195695, ess: 0.3758483318589757, Delta_free_en: 122.20361334908522\n",
            "step: 18, loss: 121.83085578967729, w_var: 3.1022007519034682, ess: 0.555399571051238, Delta_free_en: 120.91647900375398\n",
            "step: 19, loss: 122.75191808906071, w_var: 2.6921588828714897, ess: 0.6600622742093105, Delta_free_en: 122.07971483726674\n",
            "step: 20, loss: 122.03177978497435, w_var: 2.124516073852448, ess: 0.5471743930693491, Delta_free_en: 121.38292001953437\n",
            "step: 21, loss: 121.87996889539174, w_var: 2.1807158748716717, ess: 0.42460760172472767, Delta_free_en: 121.09832239849153\n",
            "step: 22, loss: 121.95773627096312, w_var: 1.012041129798355, ess: 0.5837119116916294, Delta_free_en: 121.56524348201621\n",
            "step: 23, loss: 121.87507928764884, w_var: 1.870901395850208, ess: 0.4327916874540209, Delta_free_en: 121.09985445443336\n",
            "step: 24, loss: 121.62594573675331, w_var: 4.333645721886411, ess: 0.3476829525661118, Delta_free_en: 120.43698717556236\n",
            "step: 25, loss: 122.354280087444, w_var: 1.8881550565415968, ess: 0.5914622321883912, Delta_free_en: 121.79591698618633\n",
            "step: 26, loss: 121.53329372530615, w_var: 1.679257905213093, ess: 0.3313116566600772, Delta_free_en: 120.73965610549708\n",
            "step: 27, loss: 121.94161313680286, w_var: 2.5568200093298707, ess: 0.20254346944520366, Delta_free_en: 120.62775688006519\n",
            "step: 28, loss: 121.18195707319646, w_var: 3.3550932615274363, ess: 0.4554396147323237, Delta_free_en: 120.10104995526517\n",
            "step: 29, loss: 120.80519314867263, w_var: 1.8066261646471797, ess: 0.5711172486597714, Delta_free_en: 120.2538539767634\n",
            "step: 30, loss: 120.76067915174363, w_var: 0.7318741142353782, ess: 0.4467203971049989, Delta_free_en: 120.37514361421123\n",
            "step: 31, loss: 121.02497189556514, w_var: 1.0615834757612757, ess: 0.4797657701563421, Delta_free_en: 120.5349076348297\n",
            "step: 32, loss: 121.10796467325005, w_var: 1.7997097724365727, ess: 0.5897683273385992, Delta_free_en: 120.52428866093062\n",
            "step: 33, loss: 121.75173838643147, w_var: 0.5043299800644353, ess: 0.6722557754073724, Delta_free_en: 121.52898928966\n",
            "step: 34, loss: 121.62358827766037, w_var: 1.208818158946285, ess: 0.43240104988544753, Delta_free_en: 121.10504406089963\n",
            "step: 35, loss: 122.0408296021841, w_var: 0.7627124867576259, ess: 0.6707498317479268, Delta_free_en: 121.75782090350225\n",
            "step: 36, loss: 121.30119256754561, w_var: 1.1423236198878823, ess: 0.5142665807545654, Delta_free_en: 120.80520338224744\n",
            "step: 37, loss: 121.06794863721431, w_var: 0.253710037366491, ess: 0.8065486013982281, Delta_free_en: 120.95568444897124\n",
            "step: 38, loss: 121.21775403178208, w_var: 0.8109380716885487, ess: 0.5280011621372557, Delta_free_en: 120.86195679784103\n",
            "step: 39, loss: 120.92713311500431, w_var: 0.6817241985589432, ess: 0.5571621436622158, Delta_free_en: 120.60333289354601\n",
            "step: 40, loss: 122.52706723314387, w_var: 0.9070992752126308, ess: 0.4456028474292388, Delta_free_en: 122.08699646911276\n",
            "step: 41, loss: 122.44105555209781, w_var: 1.6327712273623463, ess: 0.49148604787717187, Delta_free_en: 121.82727279810143\n",
            "step: 42, loss: 122.39649095473749, w_var: 1.579443147190956, ess: 0.28070025786016056, Delta_free_en: 121.59480289660925\n",
            "step: 43, loss: 121.98419502522816, w_var: 2.4740897764524092, ess: 0.3651885253913983, Delta_free_en: 120.96614691074909\n",
            "step: 44, loss: 120.97609591255791, w_var: 0.42117130463721036, ess: 0.6358806622234474, Delta_free_en: 120.76716480932726\n",
            "step: 45, loss: 120.85185576432983, w_var: 1.0328667582060098, ess: 0.5062103677468903, Delta_free_en: 120.4044654822304\n",
            "step: 46, loss: 121.6502032562529, w_var: 1.5295393709447462, ess: 0.7626509684907721, Delta_free_en: 121.28171228721313\n",
            "step: 47, loss: 121.0725878525553, w_var: 1.5196199877060044, ess: 0.43063467250961285, Delta_free_en: 120.46245223592139\n",
            "step: 48, loss: 121.74743960492961, w_var: 0.7082232960395908, ess: 0.6538496411077572, Delta_free_en: 121.45659201131971\n",
            "step: 49, loss: 121.3717109032039, w_var: 1.202328614249182, ess: 0.4839566041590088, Delta_free_en: 120.84799972316594\n",
            "step: 50, loss: 121.58488391156418, w_var: 0.9474163360304158, ess: 0.5787564794813387, Delta_free_en: 121.21307957457418\n",
            "step: 51, loss: 121.04385166843932, w_var: 0.5775962619859755, ess: 0.6582886081832555, Delta_free_en: 120.79015378574415\n",
            "step: 52, loss: 121.29790959106762, w_var: 0.5736159763887045, ess: 0.5295169289163528, Delta_free_en: 121.00246749755185\n",
            "step: 53, loss: 120.8347250958329, w_var: 0.8573731454538784, ess: 0.5860908887001711, Delta_free_en: 120.46942405157424\n",
            "step: 54, loss: 121.37921262461774, w_var: 0.21355934546371333, ess: 0.877319949506379, Delta_free_en: 121.29571029822851\n",
            "step: 55, loss: 121.90926475035434, w_var: 0.3307585422306745, ess: 0.7400346679845178, Delta_free_en: 121.75676609564415\n",
            "step: 56, loss: 121.60492834319727, w_var: 0.696018960488055, ess: 0.7527605293325245, Delta_free_en: 121.36745057736456\n",
            "step: 57, loss: 121.04611931000105, w_var: 0.8115809762897148, ess: 0.4774508114386579, Delta_free_en: 120.65261347689183\n",
            "step: 58, loss: 121.63799064532722, w_var: 1.1464521176110967, ess: 0.6360203433906213, Delta_free_en: 121.2418985401948\n",
            "step: 59, loss: 121.3656712271825, w_var: 0.7424349812271821, ess: 0.6476556712710712, Delta_free_en: 121.05941538898739\n",
            "step: 60, loss: 121.49313098066354, w_var: 0.40364464896203395, ess: 0.6551132263648449, Delta_free_en: 121.29556639471761\n",
            "step: 61, loss: 121.24809896943822, w_var: 1.466337788746132, ess: 0.5086785760211628, Delta_free_en: 120.70176472421926\n",
            "step: 62, loss: 121.16969887629456, w_var: 1.1452839727147268, ess: 0.4163902502063562, Delta_free_en: 120.6230363104223\n",
            "step: 63, loss: 122.16874042068343, w_var: 0.9120604369571783, ess: 0.6747269687028464, Delta_free_en: 121.84018337836623\n",
            "step: 64, loss: 121.77369179897096, w_var: 1.138056266320527, ess: 0.534533008561676, Delta_free_en: 121.3420470795614\n",
            "step: 65, loss: 121.33271105506446, w_var: 2.404379881124704, ess: 0.1880565041803224, Delta_free_en: 119.96382297437593\n",
            "step: 66, loss: 120.99844408198209, w_var: 1.7784454432560106, ess: 0.5619183823239284, Delta_free_en: 120.43945971606041\n",
            "step: 67, loss: 120.66865669654558, w_var: 1.125381598765173, ess: 0.6490334851464342, Delta_free_en: 120.28252475624647\n",
            "step: 68, loss: 121.4397232485971, w_var: 0.9400965753536509, ess: 0.6106310003455866, Delta_free_en: 121.07368846333034\n",
            "step: 69, loss: 120.73764596557857, w_var: 0.43205119548157134, ess: 0.6863049641591163, Delta_free_en: 120.53694658929348\n",
            "step: 70, loss: 121.59547256039002, w_var: 1.7035720721236574, ess: 0.3895383913486403, Delta_free_en: 120.82110483091444\n",
            "step: 71, loss: 121.26872977398443, w_var: 1.3289943554606372, ess: 0.3460069774462716, Delta_free_en: 120.61648714316247\n",
            "step: 72, loss: 120.86048985732057, w_var: 0.8415022083024495, ess: 0.7159162822042513, Delta_free_en: 120.56553924976335\n",
            "step: 73, loss: 121.2413103480601, w_var: 0.641525136205747, ess: 0.6361775376151954, Delta_free_en: 120.96897184583088\n",
            "step: 74, loss: 121.12620029238357, w_var: 0.5297288200434641, ess: 0.7148171191074931, Delta_free_en: 120.91457939653634\n",
            "step: 75, loss: 121.49442901887976, w_var: 0.46476356810100317, ess: 0.7887947703138217, Delta_free_en: 121.32257607764238\n",
            "step: 76, loss: 121.27241640857149, w_var: 1.2030755200525844, ess: 0.6989670919020927, Delta_free_en: 120.92550378765104\n",
            "step: 77, loss: 121.31101068111295, w_var: 0.4207524685370907, ess: 0.5853192251277493, Delta_free_en: 121.0882729761527\n",
            "step: 78, loss: 121.85198230526987, w_var: 1.5162911039491986, ess: 0.5819818862677305, Delta_free_en: 121.32245636595653\n",
            "step: 79, loss: 120.85646784272281, w_var: 2.247837624930601, ess: 0.4892139150926413, Delta_free_en: 120.08035941181924\n",
            "step: 80, loss: 121.72182635655986, w_var: 1.0891800763274169, ess: 0.3395601986983743, Delta_free_en: 121.12093631937014\n",
            "step: 81, loss: 121.48652647173088, w_var: 1.178816348461154, ess: 0.6643486010623811, Delta_free_en: 121.08749857321202\n",
            "step: 82, loss: 121.47548130852509, w_var: 1.345491170220457, ess: 0.3898299655037389, Delta_free_en: 120.87651775362181\n",
            "step: 83, loss: 121.67163036251205, w_var: 0.6105583238796902, ess: 0.6771354627280738, Delta_free_en: 121.4204815547593\n",
            "step: 84, loss: 121.4356759566246, w_var: 1.2878578880793534, ess: 0.7649317031496286, Delta_free_en: 121.09816371402894\n",
            "step: 85, loss: 121.12108649404468, w_var: 0.6748375554374016, ess: 0.6095641372366756, Delta_free_en: 120.82255881850224\n",
            "step: 86, loss: 121.64454940065828, w_var: 1.9520876839729806, ess: 0.3921229503385199, Delta_free_en: 120.85319717248308\n",
            "step: 87, loss: 121.16546840295942, w_var: 1.17178796461095, ess: 0.4802796927275456, Delta_free_en: 120.66001708070928\n",
            "step: 88, loss: 121.95037940379184, w_var: 0.9624704027584255, ess: 0.6757111221015613, Delta_free_en: 121.60512904880439\n",
            "step: 89, loss: 121.77900250479784, w_var: 0.9499754640872892, ess: 0.6108086264570048, Delta_free_en: 121.40320398972338\n",
            "step: 90, loss: 121.5915375115991, w_var: 0.6007799430491485, ess: 0.747008938412597, Delta_free_en: 121.36967344514115\n",
            "step: 91, loss: 121.54365797064108, w_var: 1.8761954124498523, ess: 0.6292673101780896, Delta_free_en: 121.0141828691097\n",
            "step: 92, loss: 121.89519207647687, w_var: 0.8463447857160542, ess: 0.42264813279318786, Delta_free_en: 121.4565611365912\n",
            "step: 93, loss: 121.69894046468829, w_var: 2.4924979092490753, ess: 0.3422553017713547, Delta_free_en: 120.72443482125296\n",
            "step: 94, loss: 121.6261719130498, w_var: 1.8259075000529807, ess: 0.4004732454659903, Delta_free_en: 120.95367201777161\n",
            "step: 95, loss: 120.89464978830212, w_var: 0.3368221439567662, ess: 0.6283692207471707, Delta_free_en: 120.7094959360338\n",
            "step: 96, loss: 121.77732824599968, w_var: 1.1113434838233271, ess: 0.6792911000570359, Delta_free_en: 121.41017491404426\n",
            "step: 97, loss: 121.26792836045772, w_var: 1.2092225470074482, ess: 0.5969835266016734, Delta_free_en: 120.8202241110848\n",
            "step: 98, loss: 121.57616310195353, w_var: 0.773871601891503, ess: 0.6395401212279375, Delta_free_en: 121.2748644871098\n",
            "step: 99, loss: 121.43568584982648, w_var: 1.696047040977774, ess: 0.3602838967434975, Delta_free_en: 120.70841727296555\n",
            "step: 100, loss: 120.3965473468788, w_var: 0.9251085778868956, ess: 0.5264656910441683, Delta_free_en: 119.98952471673007\n"
          ]
        }
      ],
      "source": [
        "if torch_device == 'cuda':\n",
        "    torch.cuda.empty_cache() #clean the gpu\n",
        "\n",
        "x0, s0 = prior() #thermalize replicas batch_size of prior samples\n",
        "for t in range(n_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    x0, s0 = prior(cfgs=x0) #apply one standard MCMC step to obtain new prior configurations\n",
        "    x, w, df, ess = flow(x0, s0) #forward pass of the model\n",
        "    loss=w.mean() #average Work\n",
        "    history['loss'].append(grab(loss)) #metrics\n",
        "    history['ESS'].append(grab(ess)) #metrics\n",
        "    #print metrics\n",
        "    print(f'step: {t + 1},'\n",
        "          f' loss: {grab(loss)},'\n",
        "          f' w_var: {grab(w.var())},'\n",
        "          f' ess: {grab(ess)},'\n",
        "          f' Delta_free_en: {grab(df)}')\n",
        "    loss.backward() #backward\n",
        "    optimizer.step() #gradient update\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lH_ebyDf0Pe"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JUvnYN6f0Pe"
      },
      "source": [
        "In the following we compute $\\Delta F$, ESS, $D_{\\text{KL}}$ and $Var(W)$. We will not compute the errors here; in our implementation, the errors are computed using an automatic differentiation method implemented by [pyerros](https://fjosw.github.io/pyerrors/pyerrors.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dYa7o1TWf0Pe"
      },
      "outputs": [],
      "source": [
        "#Function for testing and metrics\n",
        "from scipy.special import logsumexp\n",
        "def compute_metrics(w):\n",
        "    N = w.shape[-1]\n",
        "    logZ = logsumexp(-w,-1)\n",
        "    log_ess = 2.0 * logZ - logsumexp(-2 * w,-1)\n",
        "    ess_per_cfg = np.exp(log_ess) / N\n",
        "    logZ = logZ - np.log(N)\n",
        "    return w.mean(), w.var(), -logZ, ess_per_cfg,\n",
        "\n",
        "def measures(model,n_meas):\n",
        "    W=[]\n",
        "    x0, s0 = prior()\n",
        "    for i in (range(n_meas)):\n",
        "        x0, s0 = prior(cfgs=x0)\n",
        "        _, w = model.sample_(x0,s0)\n",
        "        W.append(grab(w))\n",
        "    W=np.asarray(W).reshape(-1)\n",
        "    return W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Mwjtoxo6f0Pe"
      },
      "outputs": [],
      "source": [
        "n_meas=100 #total number of configurations considered = n_meas * bs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tRT72crjqqIv"
      },
      "outputs": [],
      "source": [
        "#thermalization and loop over batch:\n",
        "W=measures(flow,n_meas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HCNwzkY4f0Pe"
      },
      "outputs": [],
      "source": [
        "work, var_work, DeltaF, ess= compute_metrics(W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y4aRm62f0Pe",
        "outputId": "2083e0d9-59d1-47e1-b03e-d76c6c39ff75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " work: 121.36527665185615, w_var: 1.1286510257765099, ess: 0.38155337052697996, Delta free energy: 120.81849807935748 Dkl: 0.5467785724986669\n"
          ]
        }
      ],
      "source": [
        "print(f' work: {work},'\n",
        "      f' w_var: {var_work},'\n",
        "      f' ess: {ess},'\n",
        "      f' Delta free energy: {DeltaF}'\n",
        "      f' Dkl: {work-DeltaF}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now test the performance of the underlying NE-MCMC in order to benchmark our trained model."
      ],
      "metadata": {
        "id": "Muk4zEn0x3t5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nemcmc = make_SNF(betas, action, update, mask, init_shape, jac_shape,torch_device, False)"
      ],
      "metadata": {
        "id": "sel3avgy08Fh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Wne=measures(nemcmc,n_meas)"
      ],
      "metadata": {
        "id": "oA8xor951WUs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "work, var_work, DeltaF, ess= compute_metrics(Wne)\n",
        "print(f' work: {work},'\n",
        "      f' w_var: {var_work},'\n",
        "      f' ess: {ess},'\n",
        "      f' Delta free energy: {DeltaF}'\n",
        "      f' Dkl: {work-DeltaF}')"
      ],
      "metadata": {
        "id": "nk_3-dJp3Cbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c9c123c-881a-46ca-abde-f458474a8443"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " work: 121.96895580376123, w_var: 2.610982472087628, ess: 0.14719135736681613, Delta free energy: 120.75896604787775 Dkl: 1.209989755883484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can observe, the SNF achieved roughly a factor of two/trhee improvement in the ESS compared to the NE-MCMC."
      ],
      "metadata": {
        "id": "gn1wIEap3Nt2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some suggested future implementations"
      ],
      "metadata": {
        "id": "RyQAN-T4YOem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have played with our SNF, you can try larger volumes, more steps, or different couplings. Additional implementations can include the training used in our paper, i.e., each deterministic layer is trained independently along each forward pass, or the extrapolation of the rho parameteters."
      ],
      "metadata": {
        "id": "lx9nx_jYYWeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Have fun!**"
      ],
      "metadata": {
        "id": "kzuXhKDQYyKM"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}